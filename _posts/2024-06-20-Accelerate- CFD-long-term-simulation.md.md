---
layout: post
read_time: true
show_date: true
title: "Can long-term CFD transient simulations be accelerated?"
date: 2024-06-20
img: posts/20240620/Dronn-p.jpg
img_caption: "Photo by Bent Bach"
tags: [CFD, High-performance cluster, Ansys fluent, 3D model]
category: opinion
author: Yueechen
description: "When using the commercial software Fluent for simulation, in addition to focusing on the results, time cost is also a significant factor. So can long-term CFD transient simulations be accelerated?"
---
Recently, I finished writing my master's thesis. During these six months, time has always been an important factor that bothered me. In the first three months, I actively cooperated with a Chinese university to try to develop a program specifically for pit thermal storage simulation in C++ to fundamentally accelerate the simulation and phase in the development of the information exchange code for the universal grid of the two-dimensional interface. But for various reasons, I eventually had to use the commercial software Ansys Fluent to simulate a three-dimensional model for a year, and how to speed up became the issue I considered the most in the rest three months.

First of all, HPC (high performance computing) has to be utlized, because it has become a necessary method to ensure computing efficiency and stability when performing heavy numerical computing tasks. DDC (DTU Computing Center) manages the HPC cluster and is open to all students and employees [33]. The facility runs on the Linux  system and uses the LSF (Load Sharing Facility) platform to schedule and manage jobs in the cluster.

```bash
/appl/ansys/2020R1/v201/fluent/bin/fluent 3ddp -g -t$LSB_DJOB_NUMPROC -i instruction.journal -mpi=intel -cnf=$LSB_DJOB_RANKFILE > console.out
```
The project was created by [Over the Bridge](https://overthebridge.org), an organization dedicated to increase awareness on mental health and substance abuse in the music industry, trying to denormalize and remove the glamour around such illnesses within the music community.

They are using Google's [Magenta](https://magenta.tensorflow.org), which is a neural network that precisely was conceived to explore the role of machine learning within the creative process. Magenta has been used to create a brand new "Beatles" song or even there was a band that [used it to write a full album](https://arstechnica.com/gaming/2019/08/yachts-chain-tripping-is-a-new-landmark-for-ai-music-an-album-that-doesnt-suck/) in 2019.

So, while reading the article, my immediate thought was: who owns the copyright of these new songs?

Think about it, imagine one of this new songs becomes a massive hit with millions of youtube views and spotify streams, who can claim the royalties generated?

At first it seems quite simple, *Over the Bridge* should be the ones reaping the benefits, since they are the ones who had the idea, gathered the data and then fed the neural network to get the "work of art". But in a second thought, didn't the original artists provide the basis for the work the neural network generated? shouldn't their state get credit? what about Google whose tool was used, should they get credit too?

Neural networks have been also used to create poetry, paintings and to write news articles, but how do they do it? A computer program developed for machine learning purposes is an algorithm that "learns" from data to make future decisions. When applied to art, music and literary works, machine learning algorithms are actually learning from some input data to generate a new piece of work, making independent decisions throughout the process to determine what the new work looks like. An important feature of this is that while programmers can set the parameters, the work is actually generated by the neural network itself, in a process akin to the thought processes of humans.

Now, creative works qualify for copyright protection if they are original, with most definitions of originality requiring a human author. Most jurisdictions, including [Spain](https://www.wipo.int/wipolex/en/details.jsp?id=1319) and [Germany](https://dejure.org/gesetze/UrhG/7.html), specifically state that only works created by a human can be protected by [copyright](https://www.wipo.int/copyright/en/). In the United States, for example, [the Copyright Office has declared](https://copyright.gov/comp3/chap300/ch300-copyrightable-authorship.pdf) that it will “register an original work of authorship, provided that the work was created by a human being.” 

So as we currently stand, a human author is required to grant a copyright, which makes sense, there is no point of having a neural network be the beneficiary of royalties of a creative work (no bank would open an account for them anyways, lol).

I think amendments have to be made to the law to ensure that the person who undertook all the arrangements necessary for the work to be created by the neural network gets the credit but also we need to modify copyright law to ensure the original authors of the body of work used as data input to produce the new piece get their corresponding share of credit. This will get messy if someone uses for example the #1 song of every month in a decade to create the decade song, then there would be as many as 120 different artists to credit.

<tweet>In a computer generated artistic work, both the person who undertook all the arrangements necessary for its creation as well as the original authors of the data input need to be credited.</tweet> 

There will still be some ambiguity as to who undertook the arrangements necessary, only the one who gathered the data and pressed the button to let the network learn, or does the person who created the neural network's model also get credit? Shall we go all the way and say that even the programmer of the neural network gets some credit as well?

There are some countries, in particular the UK where some progress has been made to amend copyright laws to cater for computer generated works of art, but I believe this is one of those fields where technology will surpass our law making capacity and we will live under a grey area for a while, and maybe this is just what we need, by having these works ending up free for use by anyone in the world, perhaps a new model for remunerating creative work can be established, one that does not require commercial success to be necessary for artists to make a living, and thus they can become free to explore their art.

<tweet>Perhaps a new model for remunerating creative work can be established, one that does not require commercial success to be necessary for artists to make a living.</tweet>

![The next Rembrandt](./assets/img/posts/20210420/post8-rembrandt2.jpg)
<small>[The Next Rembrandt](https://www.jwt.com/en/work/thenextrembrandt) is a computer-generated 3-D–printed painting developed by a facial-recognition algorithm that scanned data from 346 known paintings by the Dutch painter in a process lasting 18 months. The portrait is based on 168,263 fragments from Rembrandt’s works.</small>

